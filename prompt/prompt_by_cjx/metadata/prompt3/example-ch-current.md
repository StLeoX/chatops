# 故障注入测试报告分析

## 概述

此报告深入分析了涵盖`user-netdelay`、`frontend-netdelay`和`catalogue-netdelay`的三个核心故障注入演练。在这些演练中，我们专注于CPU使用率、数据包的接收与发送数量（receivePackets和transmitPackets）以及带宽（receiveBandwidth和transmitBandwidth）在关键时刻的表现，以评估系统在面对网络延迟时的表现。

## 1\. `user-netdelay` 演练分析

### 数据趋势与峰值分析

-   **CPU使用率**：
    
    -   **峰值**：显著增长至26.0%，记录于13时24分。
    -   **波动区间**：一般情况下，CPU使用率在0.17%至0.36%之间稳定波动，但在13时24分这一时刻，我们观察到一个显著的跃升至26.0%。
-   **数据包数量（receivePackets）**：
    
    -   **峰值**：在13时24分，接收数据包数量激增至73853个，发送数据包同一时间达到了102270个。
    -   **波动区间**：平常接收数据包数量稳定在343至910个，而发送数据包则在293至916个之间，但在13时24分这一关键时刻，两者都经历了显著的增长。
-   **带宽（receiveBandwidth）**：
    
    -   **峰值**：在13时24分，接收带宽急剧上升至12.73MB，而发送带宽也达到了20.34MB的顶峰。
    -   **波动区间**：一般情况下，接收带宽波动在31.5kB至80.3kB之间，发送带宽则在34.5kB至101.7kB范围内，但在13时24分，两者都呈现出了异常的峰值。

## 2\. `frontend-netdelay` 演练分析

### 数据趋势与峰值分析

-   **CPU使用率**：
    
    -   **峰值**：在13时24分触及高达63.0%的顶点。
    -   **波动区间**：通常在0.26%至0.39%之间波动，然而，在13时24分至13时28分的短时间内，CPU使用率急速攀升至63.0%。
-   **数据包数量（receivePackets）**：
    
    -   **峰值**：在13时28分，接收数据包数飙升至185449个，发送数据包数量也达到了235499个。
    -   **波动区间**：在正常情况下，接收数据包的数量维持在266至696个之间，发送数据包则在233至603个之间。但在故障注入的关键时刻，两者均显著上升。
-   **带宽（receiveBandwidth）**：
    
    -   **峰值**：在13时28分，接收带宽达到了令人瞩目的586.14MB，同时发送带宽也高达189.87MB。
    -   **波动区间**：平时接收带宽在20.9kB至55.7kB之间波动，发送带宽在31.5kB至81.9kB之间。然而，在故障注入期间，两者都经历了显著的增加。

## 3\. `catalogue-netdelay` 演练分析

### 数据趋势与峰值分析

-   **CPU使用率**：
    
    -   **峰值**：在13时24分达到了22%的峰值。
    -   **波动区间**：通常情况下，CPU使用率维持在一个较低的水平，即0.16%至0.23%，但在13时28分，我们观察到一次显著的跃升。
-   **数据包数量（receivePackets）**：
    
    -   **峰值**：在13时24分，接收数据包数量急剧上升至65566个，发送数据包数量也达到了92523个。
    -   **波动区间**：在一般情况下，接收和发送数据包数量相对稳定，但在关键时刻，两者都显著增加。
-   **带宽（receiveBandwidth）**：
    
    -   **峰值**：在13时28分，接收带宽达到了586.14MB，发送带宽也达到了189.87MB的高点。
    -   **波动区间**：平常接收带宽和发送带宽相对稳定，但在故障注入时刻，两者都出现了异常的增长。

## 总结与系统问题分析

### 用户期望分析

#### 登录模块

- **CPU使用率**：在`user-netdelay`演练中，`user-64856bf58f-7zngw`节点的CPU使用率在13时24分54秒飙升至26.0%，远低于设定的最大阈值80%，此期望满足。

#### 商品目录模块

- **网络带宽接收（receiveBandwidth）**：在`catalogue-netdelay`演练中，`catalogue-6bc98b6c5b-qlfh4`节点的接收带宽在13时28分24秒大幅上升，远超正常水平。这表明receiveBandwidth在网络延迟期间没有保持在正常水平的±20%以内，不符合用户期望。
- **网络带宽发送（transmitBandwidth）**：同样，在`catalogue-netdelay`演练中，发送带宽在13时28分24秒显著上升，违反了用户期望中transmitBandwidth应在演练期间保持稳定的要求。
- **网络包接收（receivePackets）**：`catalogue-6bc98b6c5b-qlfh4`节点在13时28分24秒接收数据包数量大幅上升，远超正常范围，不符合用户期望中receivePackets应保持在正常范围内的要求。
- **网络包发送（transmitPackets）**：同样，在13时28分24秒，发送数据包数量大幅上升，超出正常范围，违反了用户期望中transmitPackets数应保持稳定的要求。

### 系统问题分析

-   **CPU使用率突增**：在所有演练中，特定时刻的CPU使用率的显著上升表明，当系统面对故障时，资源利用率大幅提高。
-   **数据包数量和带宽的异常增加**：网络故障注入可能导致了数据传输的不稳定性，这可能源于网络拥堵或不恰当的流量管理策略。
-   **潜在问题的具体位置**：在`user-netdelay`演练中，13时24分的数据波动突出，显示了系统在应对网络延迟时的脆弱性。同样，在`frontend-netdelay`和`catalogue-netdelay`演练中，13时24分至13时28分的数据波动也指出了网络延迟方面的潜在问题。

综合来看，这些演练结果指出了系统在处理网络延迟方面的潜在缺陷，提示我们需要进一步优化网络流量管理和资源分配策略，以增强系统的稳定性和鲁棒性。